<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Imaginative-Walks</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="icon" type="image/png" href="img/seal_icon.png">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="js/app.js"></script>
</head>

<body>
<div class="container" id="main">
    <div class="row">

        <h2 class="col-md-12 text-center" style="padding-bottom:20px">

            <b>Imaginative Walks: Generative Random Walk Deviation Loss for Improved Unseen Learning Representation</br></b>
            <span style="font-size:18pt"> Under Review </span>
            <br>
        </h2>

    </div>
    <div class="row">
        <div class="col-md-12 text-center">
            <ul class="list-inline" style="font-size:18pt">
                <li>
                    <a href="https://divyanshj16.github.io/">
                        Divyansh Jha*
                    </a>
                </li>
                <li>
                    <a href="https://kaiyi.me/">
                        Kai Yi*
                    </a>
                </li>

                <li>
                    <a href="https://universome.github.io/">
                        Ivan Skorokhodov
                    </a>
                </li>
                
                <li>
                    <a href="http://www.mohamed-elhoseiny.com/">
                        Mohamed Elhoseiny
                    </a>
                </li>
                </br>King Abdullah University of Science and Technology (KAUST)
           
            </ul>

        </div>
    </div>


    <div class="row" style="padding-top:45px">
        <div class="col-md-6 col-md-offset-3 text-center">
            <ul class="nav nav-pills nav-justified">
                <li>
                    <a href="https://arxiv.org/abs/2104.09757">
                        <h4><strong>[ Paper ]</strong></h4>
                    </a>
                </li>
                <li>
                    <a href="#video">
                        <h4><strong>[ Video ]</strong></h4>
                    </a>
                </li>
                <li>
                    <a href="https://github.com/Vision-CAIR/GRaWD">
                        <h4><strong>[ Code ]</strong></h4>
                    </a>
                </li>               
            </ul>
        </div>
    </div>


    <div class="row" style="padding-bottom:30px">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Abstract</b>
            </h3>
            <p class="text-justify">
                We propose a novel loss for generative models, dubbed as GRaWD (Generative Random Walk  Deviation), to improve learning representations of unexplored visual spaces. Quality learning representation of unseen classes (or styles) is critical to facilitate novel image generation and better generative understanding of unseen visual classes, i.e., zero-shot learning (ZSL). By generating representations of unseen classes based on their semantic descriptions, e.g., attributes or text, generative ZSL attempts to differentiate unseen from seen categories.
The proposed GRaWD loss is defined by constructing a dynamic graph that includes the seen class/style centers and generated samples in the current minibatch. Our loss initiates a random walk probability from each center through visual generations produced from hallucinated unseen classes. As a deviation signal, we encourage the random walk to eventually land after $t$ steps in a feature representation that is difficult to classify as any of the seen classes. We demonstrate that the proposed loss can improve unseen class representation quality inductively on text-based ZSL benchmarks on CUB and NABirds datasets and attribute-based ZSL benchmarks on AWA2, SUN, and aPY datasets. In addition, we investigate the ability of the proposed loss to generate meaningful novel visual art on the WikiArt dataset. The results of experiments and human evaluations demonstrate that the proposed GRaWD loss can improve StyleGAN1 and StyleGAN2 generation quality and create novel art that is significantly more preferable. Our code is made publicly available at https://github.com/Vision-CAIR/GRaWD.
            </p>
        </div>
    </div>


    <div class="row" id="video" style="padding-bottom:30px">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Video</b>
            </h3>
           <video id="v0" width="100%" loop="" muted="" controls="">
               <source src="img/hi_res.mp4" type="video/mp4">
           </video>
<!--             <iframe width="100%" height="400"
                src="https://www.youtube.com/embed/yEdf24hF_sY">
            </iframe> -->

        </div>

    </div>

    
    <div class="row" style="padding-bottom:30px">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Motivation</b>
            </h3>
        </div>

        <div class="col-md-8 col-md-offset-2">
            <figure>
                <img src="img/teaser_crw_v2.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-8 col-md-offset-2">
            Generative Random Walk Deviation loss encourages generatively visiting the <span style="color:orange">orange</span> realistic space aiming to deviate from seen classes avoiding the less real <span style="color:red">red</span> space. Our loss starts from each seen class ( in <span style="color:green">green</span>) performing a random walk though generated examples of hallucinated unseen classes (in <span style="color:orange">orange</span>) for T steps. We then encourage the landing representation to be far/distinguishable from seen classes. With this property, our loss help improve generalized zero-shot learning performance.
        </div>
        
        <div class="col-md-8 col-md-offset-2">
            <figure>
                <img src="img/teaser2.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-8 col-md-offset-2">
            Our generated art images shown on top with <span style="color:orange">orange</span> borders are generated also using our loss when considering known art movements like cubism and high renaissance as seen classes. The bottom part of this figure shows the Nearest Neighbors (NN) in the training set (with <span style="color:green">green</span> borders) which are different.
        </div>
    </div>
    
    
    <div class="row" style="padding-bottom:30px">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Method: GRaWD</b>
            </h3>
        </div>

        <div class="col-md-8 col-md-offset-2">
            <figure>
                <img src="img/GRW_method_v2.jpg" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-8 col-md-offset-2">
            Generative Random Walk Deviation loss starts from each seen class center (i.e., ci). It then performs a random walk
            through generated examples of hallucinated unseen classes using G(su; z) for T steps. The landing probability distribution
            of the random walk is encouraged to be uniform over the seen classes. For careful deviation from seen classes, the generated
            images are encouraged to be classified as real by the Discriminator D.
        </div>
    </div>
    
    <div class="row" style="padding-bottom:30px">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Quantative Results in ZSL</b>
            </h3>
        </div>

        <div class="col-md-8 col-md-offset-2">
            <figure>
                <img src="img/text_results.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-8 col-md-offset-2">
            Zero-Shot Recognition from textual description on CUB and NAB datasets (Easy and Hard Splits) showing that adding GRaWD loss can improve the performance. tr means the transductive setting.
        </div>
        
                <div class="col-md-8 col-md-offset-2">
            <figure>
                <img src="img/att_results.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-8 col-md-offset-2">
            Zero-Shot Recognition on class-level attributes of AwA2, aPY and SUN datasets, showing that GRaWD loss can improve the performance on attribute-based datasets. tr means the transductive setting.
        </div>
        
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Results in Art generation</b>
            </h3>
        </div>        
        
        <div class="col-md-8 col-md-offset-2">
            <figure>
                <img src="img/Likeability.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-8 col-md-offset-2">
            Human experiments on generated art from Vanilla GAN,  GRaWD  and  CAN  losses.
            Models  trained  on  our loss has the highest mean likeability in all the groups. 
            More people believed the generated art to be real for art work gen-erated from model trained on our loss.
        </div>
        
        <div class="col-md-7 col-md-offset-3">
            <figure>
                <img src="img/most_liked_grawd.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-7 col-md-offset-3">
            Most liked art generated with Style-GAN trained on GRaWD.
        </div> 
        
        <div class="col-md-8 col-md-offset-2">
            <figure>
                <img src="img/wundt_curve_paper.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-8 col-md-offset-2">
            Empirical approximation of Wundt Curve.
            It shows that novelty will be likeable if the deviation
            from current is limited; if this deviation is large, people tend
            to dislike. The color of the data point represents a specific
            model and its label specifies the group named according to
            nomenclature in the paper.  In this figure, the art from the NN↑
            group has low likeability than the NN↓ group. Examples of a high
            and low likeability art work are shown.
        </div>
        
    </div>
    
        <div class="row" id="citation" style="padding-bottom:30px">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Citation</b>
            </h3>
            If you find our work useful in your research, please consider citing:
        <pre class="w4-panel w4-centerbar w4-light-grey" style="font-size: 11px">
@article{elhoseiny2021imaginative,
  title={Imaginative Walks: Generative Random Walk Deviation Loss for Improved Unseen Learning Representation},
  author={Elhoseiny, Mohamed and Jha, Divyansh and Yi, Kai and Skorokhodov, Ivan},
  journal={arXiv preprint arXiv:2104.09757},
  year={2021}
}</pre>
        </div>
    </div>

</html>
