<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Imaginative-Walks</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="icon" type="image/png" href="img/seal_icon.png">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="js/app.js"></script>
</head>

<body>
<div class="container" id="main">
    <div class="row">

        <h2 class="col-md-12 text-center" style="padding-bottom:20px">

            <b>Imaginative Walks: Generative Random Walk Deviation Loss for Improved Unseen Learning Representation</br></b>
            <span style="font-size:18pt"> Under Review </span>
            <br>
        </h2>

    </div>
    <div class="row">
        <div class="col-md-12 text-center">
            <ul class="list-inline" style="font-size:18pt">
                <li>
                    <a href="http://www.mohamed-elhoseiny.com/">
                        Mohamed Elhoseiny
                    </a>
                </li>
                <li>
                    <a href="https://www.linkedin.com/in/divyanshjha/?originalSubdomain=in">
                        Divyansh Jha
                    </a>
                </li>
                <li>
                    <a href="https://kaiyi.me/">
                        Kai Yi
                    </a>
                </li>

                <li>
                    <a href="https://universome.github.io/">
                        Ivan Skorokhodov
                    </a>
                </li>
                </br>King Abdullah University of Science and Technology (KAUST)
           
            </ul>

        </div>
    </div>


    <div class="row" style="padding-top:45px">
        <div class="col-md-6 col-md-offset-3 text-center">
            <ul class="nav nav-pills nav-justified">
                <li>
                    <a href="https://arxiv.org/abs/2104.09757">
                        <h4><strong>[ Paper ]</strong></h4>
                    </a>
                </li>
                <li>
                    <a href="#video">
                        <h4><strong>[ Video ]</strong></h4>
                    </a>
                </li>
                <li>
                    <a href="https://github.com/Vision-CAIR/GRaWD">
                        <h4><strong>[ Code ]</strong></h4>
                    </a>
                </li>
            </ul>
        </div>
    </div>


    <div class="row" style="padding-bottom:30px">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Abstract</b>
            </h3>
            <p class="text-justify">
                We propose a novel loss for generative models, dubbed as GRaWD (Generative Random Walk  Deviation), to improve learning representations of unexplored visual spaces.  Quality learning representation of unseen classes (or styles) is crucial to facilitate novel image generation and better generative understanding of unseen visual classes (a.k.a. Zero-Shot Learning, ZSL). By generating representations of unseen classes from their semantic descriptions, such as attributes or text, Generative ZSL aims at identifying unseen categories discriminatively from seen ones.    
                
                We define GRaWD by constructing a dynamic graph, including the seen class/style centers and generated samples in the current mini-batch.  Our loss starts a random walk probability from each center through visual generations produced from hallucinated unseen classes. As a deviation signal, we encourage the random walk to eventually land after t steps in a feature representation that is hard to classify to any of the seen classes. We show that our loss can improve unseen class representation quality on four text-based  ZSL benchmarks on CUB and NABirds datasets and three attribute-based ZSL benchmarks on AWA2, SUN, and aPY datasets. We also study our loss's ability to produce meaningful novel visual art generations on WikiArt dataset. Our experiments and human studies show that our loss can improve StyleGAN1 and StyleGAN2  generation quality, creating novel art that is significantly more preferred. 
            </p>
        </div>
    </div>


    <div class="row" id="video" style="padding-bottom:30px">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Video</b>
            </h3>
           <video id="v0" width="100%" loop="" muted="" controls="">
               <source src="img/hi_res.mp4" type="video/mp4">
           </video>
<!--             <iframe width="100%" height="400"
                src="https://www.youtube.com/embed/yEdf24hF_sY">
            </iframe> -->

        </div>

    </div>

    
    <div class="row" style="padding-bottom:30px">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Motivation</b>
            </h3>
        </div>

        <div class="col-md-8 col-md-offset-2">
            <figure>
                <img src="img/teaser_crw_v2.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-8 col-md-offset-2">
            Generative Random Walk Deviation loss encourages generatively visiting the <span style="color:orange">orange</span> realistic space aiming to deviate from seen classes avoiding the less real <span style="color:red">red</span> space. Our loss starts from each seen class ( in <span style="color:green">green</span>) performing a random walk though generated examples of hallucinated unseen classes (in <span style="color:orange">orange</span>) for T steps. We then encourage the landing representation to be far/distinguishable from seen classes. With this property, our loss help improve generalized zero-shot learning performance.
        </div>
        
        <div class="col-md-8 col-md-offset-2">
            <figure>
                <img src="img/teaser2.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-8 col-md-offset-2">
            Our generated art images shown on top with <span style="color:orange">orange</span> borders are generated also using our loss when considering known art movements like cubism and high renaissance as seen classes. The bottom part of this figure shows the Nearest Neighbors (NN) in the training set (with <span style="color:green">green</span> borders) which are different.
        </div>
    </div>
    
    
    <div class="row" style="padding-bottom:30px">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Method: GRaWD</b>
            </h3>
        </div>

        <div class="col-md-8 col-md-offset-2">
            <figure>
                <img src="img/GRW_method_v2.jpg" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-8 col-md-offset-2">
            Generative Random Walk Deviation loss starts from each seen class center (i.e., ci). It then performs a random walk
            through generated examples of hallucinated unseen classes using G(su; z) for T steps. The landing probability distribution
            of the random walk is encouraged to be uniform over the seen classes. For careful deviation from seen classes, the generated
            images are encouraged to be classified as real by the Discriminator D.
        </div>
    </div>
    
    <div class="row" style="padding-bottom:30px">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Quantative Results in ZSL</b>
            </h3>
        </div>

        <div class="col-md-8 col-md-offset-2">
            <figure>
                <img src="img/text_results.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-8 col-md-offset-2">
            Zero-Shot Recognition from textual description on CUB and NAB datasets (Easy and Hard Splits) showing that adding GRaWD loss can improve the performance. tr means the transductive setting.
        </div>
        
                <div class="col-md-8 col-md-offset-2">
            <figure>
                <img src="img/att_results.png" style="padding-bottom:10px" class="img-responsive" alt="overview">
                    <figcaption>
                    </figcaption>
            </figure>
        </div>

        <div class="col-md-8 col-md-offset-2">
            Zero-Shot Recognition on class-level attributes of AwA2, aPY and SUN datasets, showing that GRaWD loss can improve the performance on attribute-based datasets. tr means the transductive setting.
        </div>
    </div>
    
        <div class="row" id="citation" style="padding-bottom:30px">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                <b>Citation</b>
            </h3>
            If you find our work useful in your research, please consider citing:
        <pre class="w4-panel w4-centerbar w4-light-grey" style="font-size: 11px">
@article{elhoseiny2021imaginative,
  title={Imaginative Walks: Generative Random Walk Deviation Loss for Improved Unseen Learning Representation},
  author={Elhoseiny, Mohamed and Jha, Divyansh and Yi, Kai and Skorokhodov, Ivan},
  journal={arXiv preprint arXiv:2104.09757},
  year={2021}
}</pre>
        </div>
    </div>

</html>
